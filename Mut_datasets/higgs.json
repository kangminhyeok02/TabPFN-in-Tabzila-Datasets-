{"dataset": {"name": "openml__higgs__146606", "cat_idx": [], "cat_dims": [], "target_type": "binary", "num_classes": 1, "num_features": 28, "num_instances": 98050, "split_source": "openml"}, "scaler": "Quantile", "model": {"name": "TabPFNModel", "params": {}, "args": {"model_name": "TabPFNModel", "batch_size": 128, "scale_numerical_features": "Quantile", "val_batch_size": 256, "objective": "binary", "gpu_ids": [0], "use_gpu": true, "epochs": 100, "data_parallel": true, "early_stopping_rounds": 20, "dataset": "openml__higgs__146606", "cat_idx": [], "num_features": 28, "subset_features": 10, "subset_rows": 1000, "subset_features_method": "mutual_information", "subset_rows_method": "random", "cat_dims": [], "num_classes": 1, "logging_period": 100}}, "experiemnt_args": {"experiment_config": "tabzilla_experiment_config_gpu.yml", "output_dir": "./results/TabPFN_MUT/openml__higgs__146606", "write_predictions": false, "use_gpu": true, "gpu_ids": [0], "data_parallel": true, "n_random_trials": 30, "hparam_seed": 0, "n_opt_trials": 1, "batch_size": 128, "val_batch_size": 256, "scale_numerical_features": "Quantile", "early_stopping_rounds": 20, "epochs": 100, "logging_period": 100, "experiment_time_limit": 36000, "trial_time_limit": 7200, "subset_rows": 1000, "subset_features": 10, "subset_rows_method": "random", "subset_features_method": "mutual_information", "subset_random_seed": 0}, "hparam_source": "sampler_30", "trial_number": 30, "exception": "None", "timers": {"train": [0.0004993610000383342, 0.0005257139998775529, 0.0004917500000374275, 0.0004717910001090786, 0.0005551009999180678, 0.0004664730001877615, 0.00048283000000992615, 0.00047758999994584883, 0.00046308600008160283, 0.00046760899999753747], "val": [1.1335587799999303, 1.1264937300002202, 1.138447000000042, 1.1376008239999464, 1.1376137510001172, 1.1321019330000581, 1.1326404850001381, 1.146661677999873, 1.1431975089999469, 1.1453334249999898], "test": [1.1415953200000786, 1.1327448890001506, 1.134573249999903, 1.1344749029999548, 1.1261007510001946, 1.1323359339999115, 1.1407060520000414, 1.141795717999912, 1.1482490920000146, 1.1512387049999688], "train-eval": [1.136211307999929, 1.1295128500000828, 1.1346844439999586, 1.1353806129998247, 1.1370740600000317, 1.132570972999929, 1.1432084220000434, 1.1426122650000252, 1.1459015030000046, 1.1475614060000225]}, "scorers": {"train": {"Log Loss": [0.5077496907369295, 0.47709130278014994, 0.4498220326448446, 0.4305663318822534, 0.41229294104959024, 0.4432107734466334, 0.4174813624202338, 0.3896546548690883, 0.4013489342651134, 0.4535612554680356], "AUC": [0.8473421099162527, 0.8820626577293404, 0.9040242079375029, 0.9203557248718072, 0.9348989728504605, 0.9119046470881353, 0.9361809004838372, 0.9472882609184871, 0.9418913053961518, 0.9018421179534165], "Accuracy": [0.769, 0.805, 0.817, 0.843, 0.855, 0.828, 0.845, 0.859, 0.85, 0.812], "F1": [0.769, 0.805, 0.817, 0.843, 0.855, 0.828, 0.845, 0.859, 0.85, 0.8119999999999999]}, "val": {"Log Loss": [0.6197136219850583, 0.6078308006233805, 0.5941776418991679, 0.6089553893146872, 0.6134157619462933, 0.5938869375206801, 0.5980747732159097, 0.6023834598250581, 0.5892322900026813, 0.5910988554988347], "AUC": [0.7211417437188362, 0.7295831921382582, 0.7436381533297833, 0.7247906278743284, 0.7259564957802843, 0.7432791144244888, 0.7376151748398445, 0.7344362685772378, 0.7489591905891466, 0.7504921656904034], "Accuracy": [0.671, 0.67, 0.675, 0.654, 0.672, 0.674, 0.678, 0.681, 0.679, 0.7], "F1": [0.671, 0.67, 0.675, 0.654, 0.672, 0.674, 0.678, 0.681, 0.679, 0.7]}, "test": {"Log Loss": [0.5985542044150199, 0.6217444131893433, 0.5994805821534945, 0.5948606357998689, 0.6101701460265246, 0.6091988897422279, 0.595680679151169, 0.6015271222086473, 0.6028760750728765, 0.5821870761054151], "AUC": [0.7377160284649271, 0.7176582595084797, 0.7401284471769052, 0.7424117732487777, 0.7237457843184716, 0.7286392022074842, 0.7405843055622792, 0.7362516338287264, 0.7315558890448759, 0.7611503767891434], "Accuracy": [0.676, 0.669, 0.683, 0.676, 0.662, 0.675, 0.68, 0.674, 0.667, 0.688], "F1": [0.676, 0.669, 0.683, 0.676, 0.662, 0.675, 0.68, 0.674, 0.667, 0.688]}}}